CUDA 11.8 loaded
/beegfs/desy/user/bachjoer/mamba/lgatr/lib/python3.9/site-packages/numba/core/decorators.py:262: NumbaDeprecationWarning: numba.generated_jit is deprecated. Please see the documentation at: https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-generated-jit for more information and advice on a suitable replacement.
  warnings.warn(msg, NumbaDeprecationWarning)
/beegfs/desy/user/bachjoer/mamba/lgatr/lib/python3.9/site-packages/hydra/_internal/defaults_list.py:251: UserWarning: In 'toptagging': Defaults list is missing `_self_`. See https://hydra.cc/docs/1.2/upgrades/1.0_to_1.1/default_composition_order for more information
  warnings.warn(msg, UserWarning)
INFO  [lorentz-gatr] Set experiment topt_local_debug with id 1
[2024-10-21 15:12:13 I] Creating new experiment topt_local_debug/GATr_6232
[2024-10-21 15:12:13 D] Saving source to ./runs/topt_local_debug/GATr_6232/source.zip
[2024-10-21 15:12:14 I] Set experiment topt_local_debug with id 1
[2024-10-21 15:12:14 I] Using device cuda
[2024-10-21 15:12:14 I] ### Starting experiment topt_local_debug/GATr_6232 (id=1) ###
[2024-10-21 15:12:17 W] Using training.force_xformers=False, this will slow down the network by a factor of 5-10.
[2024-10-21 15:12:18 I] Instantiated model GATr with 65995 learnable parameters
[2024-10-21 15:12:18 I] Not using EMA
[2024-10-21 15:12:18 I] Creating TopTaggingDataset from data/toptagging_mini.npz
[2024-10-21 15:13:38 I] Finished creating datasets after 79.95 s = 1.33 min
[2024-10-21 15:13:38 I] Constructed dataloaders with train_batches=1, test_batches=1, val_batches=1, batch_size=128 (training), 128 (evaluation)
[2024-10-21 15:13:38 I] Starting to train for 10 iterations = 10.0 epochs on a dataset with 1 batches using early stopping with patience 100 while validating every 5000 iterations
/beegfs/desy/user/bachjoer/mamba/lgatr/lib/python3.9/site-packages/numba/core/decorators.py:262: NumbaDeprecationWarning: numba.generated_jit is deprecated. Please see the documentation at: https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-generated-jit for more information and advice on a suitable replacement.
  warnings.warn(msg, NumbaDeprecationWarning)
[2024-10-21 15:13:44 I] Finished iteration 1 after 6.12s, training time estimate: 1.02min = 0.02h
[2024-10-21 15:13:46 I] Finished training for 9 iterations = 9.0 epochs after 0.14min = 0.00h
[2024-10-21 15:13:46 W] Cannot load best model (epoch 0) from ./runs/topt_local_debug/GATr_6232/models/model_run0_it0.pt
[2024-10-21 15:13:46 I] ### Starting to evaluate model on test dataset with 100 elements, batchsize 128 ###
[2024-10-21 15:13:47 I] Accuracy on test dataset: 0.6000
[2024-10-21 15:13:47 I] AUC score on test dataset: 0.7021
[2024-10-21 15:13:47 I] Rejection rate test dataset: 6 (epsS=0.3), 4 (epsS=0.5), 2
[2024-10-21 15:13:47 I] Creating plots in ./runs/topt_local_debug/GATr_6232/plots_0
[2024-10-21 15:13:51 I] GPU RAM information: max_used = 3.29 GB, max_total = 17.1 GB
[2024-10-21 15:13:51 I] Finished experiment topt_local_debug/GATr_6232 after 1.61min = 0.03h
